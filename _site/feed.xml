<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh"><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="zh" /><updated>2020-02-28T15:19:43+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">旭的小窝</title><subtitle>这里讲我的故事
</subtitle><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><entry><title type="html">Jekyll基本用法</title><link href="http://localhost:4000/2020/02/28/%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95.html" rel="alternate" type="text/html" title="Jekyll基本用法" /><published>2020-02-28T00:00:00+09:00</published><updated>2020-02-28T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/28/%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95</id><content type="html" xml:base="http://localhost:4000/2020/02/28/%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95.html">&lt;h1 id=&quot;build命令&quot;&gt;build命令&lt;/h1&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jekyll build
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;当前文件夹中的内容将会生成到 ./_site 文件夹中。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jekyll build --destination &amp;lt;destination&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;当前文件夹中的内容将会生成到目标文件夹&lt;destination&gt;中。&lt;/destination&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jekyll build --source &amp;lt;source&amp;gt; --destination &amp;lt;destination&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;指定源文件夹&lt;source /&gt;中的内容将会生成到目标文件夹&lt;destination&gt;中。&lt;/destination&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jekyll build --watch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;当前文件夹中的内容将会生成到 ./_site 文件夹中，
查看改变，并且自动再生成。&lt;/p&gt;

&lt;h1 id=&quot;服务器命令&quot;&gt;服务器命令&lt;/h1&gt;
&lt;p&gt;Jekyll 同时也集成了一个开发用的服务器，可以让你使用浏览器在本地进行预览。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jekyll serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;一个开发服务器将会运行在 http://localhost:4000/&lt;br /&gt;
Auto-regeneration（自动再生成文件）: 开启。使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;--no-watch&lt;/code&gt; 来关闭。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jekyll serve --detach
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;功能和&lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;命令相同，但是会脱离终端在后台运行。&lt;br /&gt;
如果你想关闭服务器，可以使用&lt;code class=&quot;highlighter-rouge&quot;&gt;kill -9 1234&lt;/code&gt;命令，”1234” 是进程号（PID）。&lt;br /&gt;
如果你找不到进程号，那么就用&lt;code class=&quot;highlighter-rouge&quot;&gt;ps aux | grep jekyll&lt;/code&gt;命令来查看，然后关闭服务器。&lt;a href=&quot;http://unixhelp.ed.ac.uk/shell/jobz5.html&quot;&gt;更多&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pkill -f jekyll
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;也可以杀死后台进程&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jekyll serve --no-watch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;和 &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt; 一样，但不会监测变化。&lt;/p&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="Jekyll" /><summary type="html">build命令 jekyll build 当前文件夹中的内容将会生成到 ./_site 文件夹中。 jekyll build --destination &amp;lt;destination&amp;gt; 当前文件夹中的内容将会生成到目标文件夹中。 jekyll build --source &amp;lt;source&amp;gt; --destination &amp;lt;destination&amp;gt; 指定源文件夹中的内容将会生成到目标文件夹中。 jekyll build --watch 当前文件夹中的内容将会生成到 ./_site 文件夹中， 查看改变，并且自动再生成。 服务器命令 Jekyll 同时也集成了一个开发用的服务器，可以让你使用浏览器在本地进行预览。 jekyll serve 一个开发服务器将会运行在 http://localhost:4000/ Auto-regeneration（自动再生成文件）: 开启。使用 --no-watch 来关闭。 jekyll serve --detach 功能和jekyll serve命令相同，但是会脱离终端在后台运行。 如果你想关闭服务器，可以使用kill -9 1234命令，”1234” 是进程号（PID）。 如果你找不到进程号，那么就用ps aux | grep jekyll命令来查看，然后关闭服务器。更多. pkill -f jekyll 也可以杀死后台进程 jekyll serve --no-watch 和 jekyll serve 一样，但不会监测变化。</summary></entry><entry><title type="html">网络迷踪</title><link href="http://localhost:4000/2020/02/24/%E7%BD%91%E7%BB%9C%E8%BF%B7%E8%B8%AA.html" rel="alternate" type="text/html" title="网络迷踪" /><published>2020-02-24T00:00:00+09:00</published><updated>2020-02-24T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/24/%E3%80%8A%E7%BD%91%E7%BB%9C%E8%BF%B7%E8%B8%AA%E3%80%8B</id><content type="html" xml:base="http://localhost:4000/2020/02/24/%E7%BD%91%E7%BB%9C%E8%BF%B7%E8%B8%AA.html">&lt;p&gt;2018年的高分电影，悬疑片。&lt;br /&gt;
昨天无意之间找到了这部电影，貌似还是2018年的高分悬疑电影。&lt;/p&gt;

&lt;h2 id=&quot;故事内容&quot;&gt;故事内容&lt;/h2&gt;

&lt;h2 id=&quot;感想&quot;&gt;感想&lt;/h2&gt;
&lt;p&gt;千万不要轻易的死去，要不然平时和你不熟悉的人一下就成了和你交情要好的朋友。&lt;/p&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="观后感" /><summary type="html">2018年的高分电影，悬疑片。 昨天无意之间找到了这部电影，貌似还是2018年的高分悬疑电影。 故事内容 感想 千万不要轻易的死去，要不然平时和你不熟悉的人一下就成了和你交情要好的朋友。</summary></entry><entry><title type="html">Anaconda3教程</title><link href="http://localhost:4000/2020/02/21/Anaconda3%E5%AE%89%E8%A3%85.html" rel="alternate" type="text/html" title="Anaconda3教程" /><published>2020-02-21T00:00:00+09:00</published><updated>2020-02-21T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/21/Anaconda3%E5%AE%89%E8%A3%85</id><content type="html" xml:base="http://localhost:4000/2020/02/21/Anaconda3%E5%AE%89%E8%A3%85.html">&lt;h1 id=&quot;什么是anaconda&quot;&gt;什么是Anaconda？&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://www.anaconda.com/&quot;&gt;Anaconda&lt;/a&gt;就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;本教程在wsl下安装anaconda及使用&lt;/p&gt;

&lt;h1 id=&quot;在window的wsl系统下安装anaconda3&quot;&gt;在window的wsl系统下安装anaconda3&lt;/h1&gt;
&lt;h2 id=&quot;steps-to-install-anaconda-on-windows-ubuntu-terminal&quot;&gt;Steps to Install Anaconda on Windows Ubuntu Terminal&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Go to https://repo.continuum.io/archive to find the list of Anaconda releases&lt;/li&gt;
  &lt;li&gt;Select the release you want.下载.bash&lt;/li&gt;
  &lt;li&gt;通过wsl终端访问/mnt/*(下载的地方)&lt;/li&gt;
  &lt;li&gt;运行安装脚本
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bash Anaconda3-2019.10-Linux-x86_64.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Optionally install VS Code when prompted&lt;/li&gt;
  &lt;li&gt;Close the terminal and reopen it to reload .bash configs.&lt;/li&gt;
  &lt;li&gt;To test that it worked, run $ which python. It should print a path that has anaconda in it.&lt;/li&gt;
  &lt;li&gt;To open jupyter, type $ jupyter notebook –no-browser.&lt;br /&gt;
The no browser flag will still run Jupyter on port 8888, but it won’t pop it open automatically. it’s necessary since you don’t have a browser (probably) in your subsystem. In the terminal, it will give you a link to paste into your browser. If it worked, you should see your notebooks!&lt;/li&gt;
  &lt;li&gt;I made an alias for the juypter command by putting this command in my .bash_aliases: alias jup=’jupyter notebook –no-browser’.&lt;br /&gt;
Restart the terminal for this new command to take effect.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;the-conda-command&quot;&gt;The conda command&lt;/h1&gt;
&lt;h2 id=&quot;install-tensorflow&quot;&gt;install tensorflow&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda install tensorflow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;验证conda已被安装&quot;&gt;验证conda已被安装&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda --version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;更新conda至最新版本&quot;&gt;更新conda至最新版本&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda update conda
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;执行命令后，conda将会对版本进行比较并列出可以升级的版本。同时，也会告知用户其他相关包也会升级到相应版本。&lt;/p&gt;

&lt;p&gt;当较新的版本可以用于升级时，终端会显示 Proceed ([y]/n)? ，此时输入 y 即可进行升级。&lt;/p&gt;

&lt;h2 id=&quot;查看conda帮助信息&quot;&gt;查看conda帮助信息&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda --help
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;或&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda -h
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h1 id=&quot;管理环境&quot;&gt;管理环境&lt;/h1&gt;
&lt;h2 id=&quot;创建新环境&quot;&gt;创建新环境&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda create --name &amp;lt;env_name&amp;gt; &amp;lt;package_names&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Attention:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;env_name&gt; 即创建的环境名。建议以英文命名，且不加空格，名称两边不加尖括号“&amp;lt;&amp;gt;”。
&lt;/env_name&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;package_names&gt; 即安装在环境中的包名。名称两边不加尖括号“&amp;lt;&amp;gt;”。
&lt;/package_names&gt;
      &lt;/li&gt;
      &lt;li&gt;如果要安装指定的版本号，则只需要在包名后面以 = 和版本号的形式执行。如： conda create –name python2 python=2.7 ，即创建一个名为“python2”的环境，环境中安装版本为2.7的python。&lt;/li&gt;
      &lt;li&gt;–name 同样可以替换为 -n 。&lt;/li&gt;
      &lt;li&gt;提示：默认情况下，新创建的环境将会被保存在 /Users/&lt;user_name&gt;/anaconda3/env 目录下，其中， &lt;user_name&gt; 为当前用户的用户名。&lt;/user_name&gt;&lt;/user_name&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;切换环境&quot;&gt;切换环境&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source activate &amp;lt;env_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;或&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda activate &amp;lt;env_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;当成功切换环境之后，在该行行首将以“(env_name)”或“[env_name]”开头。其中，“env_name”为切换到的环境名。如：在macOS系统中执行 source active python2 ，即切换至名为“python2”的环境，则行首将会以(python2)开头。&lt;/p&gt;

&lt;h2 id=&quot;退出环境至root&quot;&gt;退出环境至root&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;或&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;当执行退出当前环境，回到root环境命令后，原本行首以“(env_name)”或“[env_name]”开头的字符将不再显示。&lt;/p&gt;

&lt;h2 id=&quot;显示已创建环境&quot;&gt;显示已创建环境&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda info --envs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;或&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda info -e
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;或&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda env list
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;结果中星号“*”所在行即为当前所在环境。&lt;/p&gt;

&lt;h2 id=&quot;复制环境&quot;&gt;复制环境&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda create --name &amp;lt;new_env_name&amp;gt; --clone &amp;lt;copied_env_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Attention:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;copied_env_name&gt; 即为被复制/克隆环境名。环境名两边不加尖括号“&amp;lt;&amp;gt;”。
&lt;/copied_env_name&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;new_env_name&gt; 即为复制之后新环境的名称。环境名两边不加尖括号“&amp;lt;&amp;gt;”。
&lt;/new_env_name&gt;
      &lt;/li&gt;
      &lt;li&gt;conda create –name py2 –clone python2 ，即为克隆名为“python2”的环境，克隆后的新环境名为“py2”。此时，环境中将同时存在“python2”和“py2”环境，且两个环境的配置相同。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;删除环境&quot;&gt;删除环境&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda remove --name &amp;lt;env_name&amp;gt; --all
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;管理包&quot;&gt;管理包&lt;/h1&gt;
&lt;h2 id=&quot;查找可供安装的包版本&quot;&gt;查找可供安装的包版本&lt;/h2&gt;
&lt;h3 id=&quot;精确查找&quot;&gt;精确查找&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda search --full-name &amp;lt;package_full_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Attention:
    &lt;ul&gt;
      &lt;li&gt;–full-name 为精确查找的参数。&lt;/li&gt;
      &lt;li&gt;
        &lt;package_full_name&gt; 是被查找包的全名。包名两边不加尖括号“&amp;lt;&amp;gt;”。
&lt;/package_full_name&gt;
      &lt;/li&gt;
      &lt;li&gt;例如： conda search –full-name python 即查找全名为“python”的包有哪些版本可供安装。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;模糊查找&quot;&gt;模糊查找&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda search &amp;lt;text&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;获取当前环境中已安装的包信息&quot;&gt;获取当前环境中已安装的包信息&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda list
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;执行上述命令后将在终端显示当前环境已安装包的包名及其版本号。&lt;/p&gt;

&lt;h2 id=&quot;安装包&quot;&gt;安装包&lt;/h2&gt;
&lt;h3 id=&quot;在指定环境中安装包&quot;&gt;在指定环境中安装包&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda install --name &amp;lt;env_name&amp;gt; &amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;例如： conda install –name python2 pandas 即在名为“python2”的环境中安装pandas包。&lt;/p&gt;

&lt;h3 id=&quot;在当前环境中安装包&quot;&gt;在当前环境中安装包&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda install &amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;例如： conda install pandas 即在当前环境中安装pandas包。&lt;/p&gt;

&lt;h3 id=&quot;使用pip安装包&quot;&gt;使用pip安装包&lt;/h3&gt;
&lt;h4 id=&quot;使用场景&quot;&gt;使用场景&lt;/h4&gt;
&lt;p&gt;当使用 conda install 无法进行安装时，可以使用pip进行安装。例如：see包。&lt;/p&gt;

&lt;h2 id=&quot;卸载包&quot;&gt;卸载包&lt;/h2&gt;
&lt;h3 id=&quot;卸载指定环境中的包&quot;&gt;卸载指定环境中的包&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda remove --name &amp;lt;env_name&amp;gt; &amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;例如： conda remove –name python2 pandas 即卸载名为“python2”中的pandas包。&lt;/p&gt;

&lt;h3 id=&quot;卸载当前环境中的包&quot;&gt;卸载当前环境中的包&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda remove &amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;例如： conda remove pandas 即在当前环境中卸载pandas包。&lt;/p&gt;

&lt;h2 id=&quot;更新包&quot;&gt;更新包&lt;/h2&gt;
&lt;h3 id=&quot;更新所有包&quot;&gt;更新所有包&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda update --all
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;或&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda upgrade --all
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;更新指定包&quot;&gt;更新指定包&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda update &amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;或&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda upgrade &amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;更新多个指定包，则包名以空格隔开，向后排列。&lt;br /&gt;
如： conda update pandas numpy matplotlib 即更新pandas、numpy、matplotlib包。&lt;/p&gt;

&lt;h1 id=&quot;参考资料&quot;&gt;参考资料&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32925500&quot;&gt;Anaconda介绍、安装及使用教程&lt;/a&gt;&lt;/p&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="Anaconda3" /><category term="ComputerVision" /><summary type="html">什么是Anaconda？ Anaconda就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。 本教程在wsl下安装anaconda及使用 在window的wsl系统下安装anaconda3 Steps to Install Anaconda on Windows Ubuntu Terminal Go to https://repo.continuum.io/archive to find the list of Anaconda releases Select the release you want.下载.bash 通过wsl终端访问/mnt/*(下载的地方) 运行安装脚本 bash Anaconda3-2019.10-Linux-x86_64.sh Optionally install VS Code when prompted Close the terminal and reopen it to reload .bash configs. To test that it worked, run $ which python. It should print a path that has anaconda in it. To open jupyter, type $ jupyter notebook –no-browser. The no browser flag will still run Jupyter on port 8888, but it won’t pop it open automatically. it’s necessary since you don’t have a browser (probably) in your subsystem. In the terminal, it will give you a link to paste into your browser. If it worked, you should see your notebooks! I made an alias for the juypter command by putting this command in my .bash_aliases: alias jup=’jupyter notebook –no-browser’. Restart the terminal for this new command to take effect. The conda command install tensorflow conda install tensorflow 验证conda已被安装 conda --version 更新conda至最新版本 conda update conda 执行命令后，conda将会对版本进行比较并列出可以升级的版本。同时，也会告知用户其他相关包也会升级到相应版本。 当较新的版本可以用于升级时，终端会显示 Proceed ([y]/n)? ，此时输入 y 即可进行升级。 查看conda帮助信息 conda --help 或 conda -h 管理环境 创建新环境 conda create --name &amp;lt;env_name&amp;gt; &amp;lt;package_names&amp;gt; Attention: 即创建的环境名。建议以英文命名，且不加空格，名称两边不加尖括号“&amp;lt;&amp;gt;”。 即安装在环境中的包名。名称两边不加尖括号“&amp;lt;&amp;gt;”。 如果要安装指定的版本号，则只需要在包名后面以 = 和版本号的形式执行。如： conda create –name python2 python=2.7 ，即创建一个名为“python2”的环境，环境中安装版本为2.7的python。 –name 同样可以替换为 -n 。 提示：默认情况下，新创建的环境将会被保存在 /Users//anaconda3/env 目录下，其中， 为当前用户的用户名。 切换环境 source activate &amp;lt;env_name&amp;gt; 或 conda activate &amp;lt;env_name&amp;gt; 当成功切换环境之后，在该行行首将以“(env_name)”或“[env_name]”开头。其中，“env_name”为切换到的环境名。如：在macOS系统中执行 source active python2 ，即切换至名为“python2”的环境，则行首将会以(python2)开头。 退出环境至root source deactivate 或 conda deactivate 当执行退出当前环境，回到root环境命令后，原本行首以“(env_name)”或“[env_name]”开头的字符将不再显示。 显示已创建环境 conda info --envs 或 conda info -e 或 conda env list 结果中星号“*”所在行即为当前所在环境。 复制环境 conda create --name &amp;lt;new_env_name&amp;gt; --clone &amp;lt;copied_env_name&amp;gt; Attention: 即为被复制/克隆环境名。环境名两边不加尖括号“&amp;lt;&amp;gt;”。 即为复制之后新环境的名称。环境名两边不加尖括号“&amp;lt;&amp;gt;”。 conda create –name py2 –clone python2 ，即为克隆名为“python2”的环境，克隆后的新环境名为“py2”。此时，环境中将同时存在“python2”和“py2”环境，且两个环境的配置相同。 删除环境 conda remove --name &amp;lt;env_name&amp;gt; --all 管理包 查找可供安装的包版本 精确查找 conda search --full-name &amp;lt;package_full_name&amp;gt; Attention: –full-name 为精确查找的参数。 是被查找包的全名。包名两边不加尖括号“&amp;lt;&amp;gt;”。 例如： conda search –full-name python 即查找全名为“python”的包有哪些版本可供安装。 模糊查找 conda search &amp;lt;text&amp;gt; 获取当前环境中已安装的包信息 conda list 执行上述命令后将在终端显示当前环境已安装包的包名及其版本号。 安装包 在指定环境中安装包 conda install --name &amp;lt;env_name&amp;gt; &amp;lt;package_name&amp;gt; 例如： conda install –name python2 pandas 即在名为“python2”的环境中安装pandas包。 在当前环境中安装包 conda install &amp;lt;package_name&amp;gt; 例如： conda install pandas 即在当前环境中安装pandas包。 使用pip安装包 使用场景 当使用 conda install 无法进行安装时，可以使用pip进行安装。例如：see包。 卸载包 卸载指定环境中的包 conda remove --name &amp;lt;env_name&amp;gt; &amp;lt;package_name&amp;gt; 例如： conda remove –name python2 pandas 即卸载名为“python2”中的pandas包。 卸载当前环境中的包 conda remove &amp;lt;package_name&amp;gt; 例如： conda remove pandas 即在当前环境中卸载pandas包。 更新包 更新所有包 conda update --all 或 conda upgrade --all 更新指定包 conda update &amp;lt;package_name&amp;gt; 或 conda upgrade &amp;lt;package_name&amp;gt; 更新多个指定包，则包名以空格隔开，向后排列。 如： conda update pandas numpy matplotlib 即更新pandas、numpy、matplotlib包。 参考资料 Anaconda介绍、安装及使用教程</summary></entry><entry><title type="html">神经网络入门</title><link href="http://localhost:4000/2020/02/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8.html" rel="alternate" type="text/html" title="神经网络入门" /><published>2020-02-21T00:00:00+09:00</published><updated>2020-02-21T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8</id><content type="html" xml:base="http://localhost:4000/2020/02/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8.html">&lt;h1 id=&quot;神经网络刨析&quot;&gt;神经网络刨析&lt;/h1&gt;
&lt;p&gt;训练神经网络主要围绕一下几个方面：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;层&lt;/strong&gt;，多个层组合成网络（模型）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;输入数据&lt;/strong&gt;和相应的&lt;strong&gt;目标&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;损失函数&lt;/strong&gt;，用于学习的反馈信号&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;优化器&lt;/strong&gt;，决定学习过程如何进行&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;层深度学习的基础组件&quot;&gt;层：深度学习的基础组件&lt;/h2&gt;
&lt;p&gt;将一个或多个输入张量转换为一个或多个输出张量。&lt;br /&gt;
层的&lt;strong&gt;权重&lt;/strong&gt;是层的状态。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;简单的向量数据-2D张量-&lt;strong&gt;密集连接层（densely connected lyaer）或全连接层（fully connected layer)或密集层（dense layer）&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;序列数据-3D张量-&lt;strong&gt;循环层（recurrent layer）&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;图像数据-4D张量-&lt;strong&gt;二维卷积层&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;模型层构成的网络&quot;&gt;模型：层构成的网络&lt;/h2&gt;
&lt;p&gt;常见的网络拓扑结构：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;双分支网络（two-branch）&lt;/li&gt;
  &lt;li&gt;多头网络（multihead）&lt;/li&gt;
  &lt;li&gt;Inception模块&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;网络的拓扑结构定义了一个&lt;strong&gt;假设空间（hypothesis space）&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;损失函数与优化器配置学习过程的关键&quot;&gt;损失函数与优化器：配置学习过程的关键&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;损失函数（目标函数）：在训练过程中需要将其最小化。它能够衡量当前任务是否已经成功完成。&lt;/li&gt;
  &lt;li&gt;优化器：决定如何基于损失函数对网络进行更新。它执行的是随机梯度下降（SGD）的某个变体&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;梯度下降过程必须基于&lt;strong&gt;单个&lt;/strong&gt;标量损失值。&lt;/p&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="ComputerVision" /><category term="Python深度学习" /><summary type="html">神经网络刨析 训练神经网络主要围绕一下几个方面： 层，多个层组合成网络（模型） 输入数据和相应的目标 损失函数，用于学习的反馈信号 优化器，决定学习过程如何进行 层：深度学习的基础组件 将一个或多个输入张量转换为一个或多个输出张量。 层的权重是层的状态。 简单的向量数据-2D张量-密集连接层（densely connected lyaer）或全连接层（fully connected layer)或密集层（dense layer） 序列数据-3D张量-循环层（recurrent layer） 图像数据-4D张量-二维卷积层 模型：层构成的网络 常见的网络拓扑结构： 双分支网络（two-branch） 多头网络（multihead） Inception模块 网络的拓扑结构定义了一个假设空间（hypothesis space）。 损失函数与优化器：配置学习过程的关键 损失函数（目标函数）：在训练过程中需要将其最小化。它能够衡量当前任务是否已经成功完成。 优化器：决定如何基于损失函数对网络进行更新。它执行的是随机梯度下降（SGD）的某个变体 梯度下降过程必须基于单个标量损失值。</summary></entry><entry><title type="html">神经网络基础</title><link href="http://localhost:4000/2020/02/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80.html" rel="alternate" type="text/html" title="神经网络基础" /><published>2020-02-18T00:00:00+09:00</published><updated>2020-02-18T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80</id><content type="html" xml:base="http://localhost:4000/2020/02/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80.html">&lt;h1 id=&quot;神经网络的数据表示&quot;&gt;神经网络的数据表示&lt;/h1&gt;

&lt;h2 id=&quot;张量tensor&quot;&gt;张量（tensor）&lt;/h2&gt;
&lt;p&gt;使用张量作为基本数据结构。&lt;/p&gt;

&lt;p&gt;是一个数据容器。&lt;br /&gt;
它包含的数据几乎总是数值数据，因此它是数字的容器。&lt;br /&gt;
矩阵是二维张量。&lt;/p&gt;

&lt;p&gt;张量是矩阵向任意维度的推广。
张量的 &lt;strong&gt;维度（dimension)&lt;/strong&gt; 叫做 &lt;strong&gt;轴（axis）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;标量（0D张量）&lt;br /&gt;
仅包含一个数字的张量叫做 &lt;strong&gt;标量(scalar)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;向量（1D张量）&lt;br /&gt;
数字组成的数组叫做 &lt;strong&gt;向量(vector)&lt;/strong&gt; 或 &lt;strong&gt;一维张量（1D张量）&lt;/strong&gt;&lt;br /&gt;
一维张量只有一个轴。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;矩阵（2D张量）&lt;br /&gt;
向量组成的数组叫做 &lt;strong&gt;矩阵（matrix）&lt;/strong&gt; 或 &lt;strong&gt;二维张量（2D张量）&lt;/strong&gt;&lt;br /&gt;
矩阵有两个轴（行和列）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;3D张量与更高维度的张量
将多个矩阵组合成一个新的数组，可以得到一个3D张量。&lt;br /&gt;
直观的理解为数字组成的立方体。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;高维度张量以此类推。&lt;/p&gt;

&lt;h2 id=&quot;关键属性&quot;&gt;关键属性&lt;/h2&gt;
&lt;p&gt;张量由以下三个关键属性来定义。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;轴的个数（阶）&lt;br /&gt;
3D张量有3个轴，矩阵有2个轴。&lt;/li&gt;
  &lt;li&gt;形状&lt;br /&gt;
张量沿每个轴的维度大小（元素个数）。&lt;/li&gt;
  &lt;li&gt;数据类型&lt;br /&gt;
张量中所包含数据的类型。&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;很多库中不存在字符串张量。&lt;/p&gt;

&lt;h2 id=&quot;数据批量&quot;&gt;数据批量&lt;/h2&gt;
&lt;p&gt;数据张量的第一个轴（0轴）都是&lt;strong&gt;样本轴（sample axis，样本维度）&lt;/strong&gt;。
深度学习模型不会同时处理整个数据集，而是将数据拆分成小批量。&lt;br /&gt;
对于这种批量张量，第一个轴（0轴)叫做&lt;strong&gt;批量轴（batch axis）&lt;/strong&gt;或&lt;strong&gt;批量维度（batch dimension）&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;现实世界中的数据张量&quot;&gt;现实世界中的数据张量&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;向量数据：2D张量&lt;/li&gt;
  &lt;li&gt;时间序列数据 或 序列数据：3D张量&lt;/li&gt;
  &lt;li&gt;图像：4D张量&lt;/li&gt;
  &lt;li&gt;视频：5D张量&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;张量运算&quot;&gt;张量运算&lt;/h1&gt;
&lt;h2 id=&quot;逐元素运算&quot;&gt;逐元素运算&lt;/h2&gt;
&lt;h2 id=&quot;广播&quot;&gt;广播&lt;/h2&gt;
&lt;p&gt;两个形状不同的张量进行操作，会发生什么？&lt;/p&gt;

&lt;p&gt;较小的张量会被&lt;strong&gt;广播（broadcast）&lt;/strong&gt;，以匹配较大张量的形状。&lt;/p&gt;

&lt;p&gt;广播包含以下两个步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;向较小的张量添加轴（叫做&lt;strong&gt;广播轴&lt;/strong&gt;）。&lt;/li&gt;
  &lt;li&gt;将较小的张量沿着新轴重复，使其形状与较大张量相同。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;张量点积&quot;&gt;张量点积&lt;/h2&gt;
&lt;p&gt;点积运算，也叫&lt;strong&gt;张量积（tensor product）&lt;/strong&gt;。&lt;br /&gt;
它将输入张量的元素合并在一起。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;z = np.dot(x,y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;数学符号中&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;z = x.y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p class=&quot;warning&quot;&gt;两个向量之间的点积是一个标量，而且只有元素个数相同的向量之间才能做点积。&lt;/p&gt;

&lt;h2 id=&quot;张量变形tensor-reshaping&quot;&gt;张量变形（tensor reshaping）&lt;/h2&gt;
&lt;p&gt;张量变形是指改变张量的行和列，以得到想要的形状。&lt;/p&gt;

&lt;p&gt;特殊的张量变形：转置（transposition）。&lt;/p&gt;

&lt;h1 id=&quot;基于梯度的优化&quot;&gt;基于梯度的优化&lt;/h1&gt;
&lt;h2 id=&quot;训练循环training-loop&quot;&gt;训练循环（training loop)&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;抽取训练样本x和对应目标y组成的数据批量&lt;/li&gt;
  &lt;li&gt;在x上运行网络[前向传播（forward pass）]，得到预测值y_pred&lt;/li&gt;
  &lt;li&gt;计算网络在这批数据上的损失，用于衡量y_pred和y之间的距离。&lt;/li&gt;
  &lt;li&gt;更新网络的所有权重，使网络在这批数据上的损失略微下降。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于第四步，更好的方法是利用网络中所有运算都是 &lt;strong&gt;可微（differentiable）&lt;/strong&gt; 的，计算损失相对于网络系数的 &lt;strong&gt;梯度（gradient）&lt;/strong&gt;，然后向梯度的反方向改变系数，从而使损失降低。&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;可微的意思是“可以被求导”&lt;/p&gt;

&lt;h2 id=&quot;张量运算的导数梯度&quot;&gt;张量运算的导数：梯度&lt;/h2&gt;
&lt;h2 id=&quot;随机梯度下降&quot;&gt;随机梯度下降&lt;/h2&gt;
&lt;h3 id=&quot;小批量随机梯度下降mini-batch-stochastic-gradient-descent&quot;&gt;小批量随机梯度下降（mini-batch stochastic gradient descent）&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;抽取训练样本x和对应目标y组成的数据批量&lt;/li&gt;
  &lt;li&gt;在x上运行网络，得到预测值y_pred&lt;/li&gt;
  &lt;li&gt;计算网络在这批数据上的损失，用于衡量y_pred和y之间的距离。&lt;/li&gt;
  &lt;li&gt;计算损失相对于网络参数的梯度【一次**反向传播（backward pass）】。&lt;/li&gt;
  &lt;li&gt;将参数沿着梯度的反方向移动一点，从而使这批数据上的损失减小一点。&lt;/li&gt;
&lt;/ol&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;随机（stochastic）&lt;/strong&gt;是指每批数据都是随机抽取的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;真SGD&lt;/strong&gt;：每次迭代时只抽取一个样本和目标。&lt;br /&gt;
&lt;strong&gt;批量SGD&lt;/strong&gt;：每一次迭代都在所有数据上运行。这样每次更新都更加准确，但计算代价也高很多。&lt;/p&gt;

&lt;p&gt;SGD还有很多种变体，带动量的SGD等变体，被称为&lt;strong&gt;优化方法（optimization method）&lt;/strong&gt;或 &lt;strong&gt;优化器（optimizer）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;动量方法的实现过程是，每一步都移动小球，不仅要考虑当前的斜率值（当前的加速度），还要考虑当前的速度（来自于之前的加速度）。&lt;br /&gt;
在神经网络中，更新参数w不仅要考虑当前的梯度值，还要考虑上一次的参数更新。&lt;/p&gt;

&lt;h2 id=&quot;链式求导反向传播算法&quot;&gt;链式求导：反向传播算法&lt;/h2&gt;

&lt;h2 id=&quot;tips&quot;&gt;Tips：&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;学习&lt;/strong&gt;是指找到一组模型参数，使得在给定的训练数据样本和对应目标值上的损失函数最小化。&lt;/li&gt;
  &lt;li&gt;学习的过程：随机选取包含数据样本及其目标值的批量，并计算批量损失相对于网络参数的梯度。随后将网络参数沿着梯度的反方向稍稍移动。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;损失&lt;/strong&gt;是在训练过程中需要最小化额量，它能够衡量当前任务是否已成功解决。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;优化器&lt;/strong&gt;是使用损失梯度更新参数的具体方式。&lt;/li&gt;
&lt;/ul&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="ComputerVision" /><category term="Python深度学习" /><summary type="html">神经网络的数据表示 张量（tensor） 使用张量作为基本数据结构。 是一个数据容器。 它包含的数据几乎总是数值数据，因此它是数字的容器。 矩阵是二维张量。 张量是矩阵向任意维度的推广。 张量的 维度（dimension) 叫做 轴（axis） 标量（0D张量） 仅包含一个数字的张量叫做 标量(scalar) 向量（1D张量） 数字组成的数组叫做 向量(vector) 或 一维张量（1D张量） 一维张量只有一个轴。 矩阵（2D张量） 向量组成的数组叫做 矩阵（matrix） 或 二维张量（2D张量） 矩阵有两个轴（行和列） 3D张量与更高维度的张量 将多个矩阵组合成一个新的数组，可以得到一个3D张量。 直观的理解为数字组成的立方体。 高维度张量以此类推。 关键属性 张量由以下三个关键属性来定义。 轴的个数（阶） 3D张量有3个轴，矩阵有2个轴。 形状 张量沿每个轴的维度大小（元素个数）。 数据类型 张量中所包含数据的类型。 很多库中不存在字符串张量。 数据批量 数据张量的第一个轴（0轴）都是样本轴（sample axis，样本维度）。 深度学习模型不会同时处理整个数据集，而是将数据拆分成小批量。 对于这种批量张量，第一个轴（0轴)叫做批量轴（batch axis）或批量维度（batch dimension）。 现实世界中的数据张量 向量数据：2D张量 时间序列数据 或 序列数据：3D张量 图像：4D张量 视频：5D张量 张量运算 逐元素运算 广播 两个形状不同的张量进行操作，会发生什么？ 较小的张量会被广播（broadcast），以匹配较大张量的形状。 广播包含以下两个步骤： 向较小的张量添加轴（叫做广播轴）。 将较小的张量沿着新轴重复，使其形状与较大张量相同。 张量点积 点积运算，也叫张量积（tensor product）。 它将输入张量的元素合并在一起。 z = np.dot(x,y) 数学符号中 z = x.y 两个向量之间的点积是一个标量，而且只有元素个数相同的向量之间才能做点积。 张量变形（tensor reshaping） 张量变形是指改变张量的行和列，以得到想要的形状。 特殊的张量变形：转置（transposition）。 基于梯度的优化 训练循环（training loop) 抽取训练样本x和对应目标y组成的数据批量 在x上运行网络[前向传播（forward pass）]，得到预测值y_pred 计算网络在这批数据上的损失，用于衡量y_pred和y之间的距离。 更新网络的所有权重，使网络在这批数据上的损失略微下降。 对于第四步，更好的方法是利用网络中所有运算都是 可微（differentiable） 的，计算损失相对于网络系数的 梯度（gradient），然后向梯度的反方向改变系数，从而使损失降低。 可微的意思是“可以被求导” 张量运算的导数：梯度 随机梯度下降 小批量随机梯度下降（mini-batch stochastic gradient descent） 抽取训练样本x和对应目标y组成的数据批量 在x上运行网络，得到预测值y_pred 计算网络在这批数据上的损失，用于衡量y_pred和y之间的距离。 计算损失相对于网络参数的梯度【一次**反向传播（backward pass）】。 将参数沿着梯度的反方向移动一点，从而使这批数据上的损失减小一点。 随机（stochastic）是指每批数据都是随机抽取的。 真SGD：每次迭代时只抽取一个样本和目标。 批量SGD：每一次迭代都在所有数据上运行。这样每次更新都更加准确，但计算代价也高很多。 SGD还有很多种变体，带动量的SGD等变体，被称为优化方法（optimization method）或 优化器（optimizer）。 动量方法的实现过程是，每一步都移动小球，不仅要考虑当前的斜率值（当前的加速度），还要考虑当前的速度（来自于之前的加速度）。 在神经网络中，更新参数w不仅要考虑当前的梯度值，还要考虑上一次的参数更新。 链式求导：反向传播算法 Tips： 学习是指找到一组模型参数，使得在给定的训练数据样本和对应目标值上的损失函数最小化。 学习的过程：随机选取包含数据样本及其目标值的批量，并计算批量损失相对于网络参数的梯度。随后将网络参数沿着梯度的反方向稍稍移动。 损失是在训练过程中需要最小化额量，它能够衡量当前任务是否已成功解决。 优化器是使用损失梯度更新参数的具体方式。</summary></entry><entry><title type="html">最优化笔记</title><link href="http://localhost:4000/2020/02/18/%E6%9C%80%E4%BC%98%E5%8C%96.html" rel="alternate" type="text/html" title="最优化笔记" /><published>2020-02-18T00:00:00+09:00</published><updated>2020-02-18T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/18/%E6%9C%80%E4%BC%98%E5%8C%96</id><content type="html" xml:base="http://localhost:4000/2020/02/18/%E6%9C%80%E4%BC%98%E5%8C%96.html">&lt;h1 id=&quot;cs231n-optimization&quot;&gt;cs231n optimization&lt;/h1&gt;
&lt;p&gt;Optimization is the process of finding the set of parameters W that minimize the loss function.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit&quot;&gt;(知乎)最优化笔记&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://cs231n.github.io/optimization-1/&quot;&gt;cs231n&lt;/a&gt;&lt;/p&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="ComputerVision" /><category term="cs231n" /><summary type="html">cs231n optimization Optimization is the process of finding the set of parameters W that minimize the loss function. (知乎)最优化笔记 cs231n</summary></entry><entry><title type="html">PyTorch张量</title><link href="http://localhost:4000/2020/02/17/Pytorch.html" rel="alternate" type="text/html" title="PyTorch张量" /><published>2020-02-17T00:00:00+09:00</published><updated>2020-02-17T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/17/Pytorch</id><content type="html" xml:base="http://localhost:4000/2020/02/17/Pytorch.html">&lt;h1 id=&quot;基本数据类型&quot;&gt;基本数据类型&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;标量（0维）&lt;br /&gt;
一维长度为1的张量确实也可以表示张量
为了语义更清晰，在版本PyTorch0.3之后，两个概念从形式上加以区分，并增加了长度为零的 tensor。&lt;/li&gt;
  &lt;li&gt;张量（1维） Bias or Linear input （单张图片输入）&lt;/li&gt;
  &lt;li&gt;张量（2维） Linear input batch （多张图片输入）&lt;/li&gt;
  &lt;li&gt;张量（3维） RNN input Batch （循环神经网络批量输入）
[word,sentence,feature]&lt;/li&gt;
  &lt;li&gt;张量（4维） CNN input Batch （卷积神经网络批量输入）
[batch,channel,height,width] ’r’,’g’,’b’三原色通道&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;张量-tensors&quot;&gt;张量 Tensors&lt;/h1&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from __future__ import print_function
import torch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;引入pytorch&lt;/p&gt;

&lt;h3 id=&quot;创建一个-5x3-矩阵-但是未初始化&quot;&gt;创建一个 5x3 矩阵, 但是未初始化:&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = torch.empty(5, 3)
print(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;创建一个随机初始化的矩阵&quot;&gt;创建一个随机初始化的矩阵:&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = torch.rand(5, 3)
print(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;创建一个0填充的矩阵数据类型为long&quot;&gt;创建一个0填充的矩阵，数据类型为long:&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = torch.zeros(5, 3, dtype=torch.long)
print(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;创建tensor并使用现有数据初始化&quot;&gt;创建tensor并使用现有数据初始化:&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = torch.tensor([5.5, 3])
print(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;根据现有的张量创建张量&quot;&gt;根据现有的张量创建张量:&lt;/h3&gt;
&lt;p&gt;这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = x.new_ones(5, 3, dtype=torch.double)      # new_* 方法来创建对象
print(x)

x = torch.randn_like(x, dtype=torch.float)    # 覆盖 dtype!
print(x)                                      #  对象的size 是相同的，只是值和类型发生了变化
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;获取size&quot;&gt;获取size&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(x.size())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;加法&quot;&gt;加法&lt;/h1&gt;
&lt;h3 id=&quot;加法1&quot;&gt;加法1&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;y = torch.rand(5, 3)
print(x + y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tensor([[ 0.2218,  0.8329, -1.3406],
        [-0.2737,  0.8382,  1.4644],
        [-0.3806,  0.2332, -0.4300],
        [-0.6603,  1.8713,  1.9648],
        [ 1.4351, -0.6195, -0.5985]])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;加法2&quot;&gt;加法2&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(torch.add(x, y))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;提供输出tensor作为参数&quot;&gt;提供输出tensor作为参数&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;result = torch.empty(5, 3)
torch.add(x, y, out=result)
print(result)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;替换&quot;&gt;替换&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# adds x to y
y.add_(x)
print(y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p class=&quot;warning&quot;&gt;任何 以&lt;code class=&quot;highlighter-rouge&quot;&gt;_&lt;/code&gt; 结尾的操作都会用结果替换原变量. 例如: &lt;code class=&quot;highlighter-rouge&quot;&gt;x.copy_(y)&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;x.t_()&lt;/code&gt;, 都会改变 &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;使用索引操作张量&quot;&gt;使用索引操作张量&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(x[:, 1])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tensor([ 1.6401,  0.3637,  1.5745, -1.9971,  1.2926])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;torchview-改变张量的维度和大小&quot;&gt;torch.view 改变张量的维度和大小&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = torch.randn(4, 4)
y = x.view(16)
z = x.view(-1, 8)  #  size -1 从其他维度推断
print(x.size(), y.size(), z.size())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;如果你有只有一个元素的张量&quot;&gt;如果你有只有一个元素的张量&lt;/h3&gt;
&lt;p&gt;使用.item()来得到Python数据类型的数值&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = torch.randn(1)
print(x)
print(x.item())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tensor([-0.4353])
-0.43528521060943604
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="ComputerVision" /><category term="PyTorch" /><summary type="html">基本数据类型 标量（0维） 一维长度为1的张量确实也可以表示张量 为了语义更清晰，在版本PyTorch0.3之后，两个概念从形式上加以区分，并增加了长度为零的 tensor。 张量（1维） Bias or Linear input （单张图片输入） 张量（2维） Linear input batch （多张图片输入） 张量（3维） RNN input Batch （循环神经网络批量输入） [word,sentence,feature] 张量（4维） CNN input Batch （卷积神经网络批量输入） [batch,channel,height,width] ’r’,’g’,’b’三原色通道 张量 Tensors from __future__ import print_function import torch 引入pytorch 创建一个 5x3 矩阵, 但是未初始化: x = torch.empty(5, 3) print(x) 创建一个随机初始化的矩阵: x = torch.rand(5, 3) print(x) 创建一个0填充的矩阵，数据类型为long: x = torch.zeros(5, 3, dtype=torch.long) print(x) 创建tensor并使用现有数据初始化: x = torch.tensor([5.5, 3]) print(x) 根据现有的张量创建张量: 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖 x = x.new_ones(5, 3, dtype=torch.double) # new_* 方法来创建对象 print(x) x = torch.randn_like(x, dtype=torch.float) # 覆盖 dtype! print(x) # 对象的size 是相同的，只是值和类型发生了变化 获取size print(x.size()) 加法 加法1 y = torch.rand(5, 3) print(x + y) tensor([[ 0.2218, 0.8329, -1.3406], [-0.2737, 0.8382, 1.4644], [-0.3806, 0.2332, -0.4300], [-0.6603, 1.8713, 1.9648], [ 1.4351, -0.6195, -0.5985]]) 加法2 print(torch.add(x, y)) 提供输出tensor作为参数 result = torch.empty(5, 3) torch.add(x, y, out=result) print(result) 替换 # adds x to y y.add_(x) print(y) 任何 以_ 结尾的操作都会用结果替换原变量. 例如: x.copy_(y), x.t_(), 都会改变 x. 使用索引操作张量 print(x[:, 1]) tensor([ 1.6401, 0.3637, 1.5745, -1.9971, 1.2926]) torch.view 改变张量的维度和大小 x = torch.randn(4, 4) y = x.view(16) z = x.view(-1, 8) # size -1 从其他维度推断 print(x.size(), y.size(), z.size()) 如果你有只有一个元素的张量 使用.item()来得到Python数据类型的数值 x = torch.randn(1) print(x) print(x.item()) tensor([-0.4353]) -0.43528521060943604</summary></entry><entry><title type="html">自动求导</title><link href="http://localhost:4000/2020/02/17/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC.html" rel="alternate" type="text/html" title="自动求导" /><published>2020-02-17T00:00:00+09:00</published><updated>2020-02-17T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/17/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC</id><content type="html" xml:base="http://localhost:4000/2020/02/17/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC.html">&lt;h1 id=&quot;autograd-自动求导机制&quot;&gt;Autograd: 自动求导机制&lt;/h1&gt;
&lt;p&gt;PyTorch 中所有神经网络的核心是 autograd 包。&lt;/p&gt;

&lt;p&gt;autograd包为张量上的所有操作提供了自动求导。 它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。&lt;/p&gt;

&lt;h2 id=&quot;张量torchtensor&quot;&gt;张量（torch.Tensor）&lt;/h2&gt;
&lt;p&gt;torch.Tensor是这个包的核心类。&lt;/p&gt;

&lt;p&gt;如果设置 .requires_grad 为 True，那么将会追踪所有对于该张量的操作。&lt;br /&gt;
当完成计算后通过调用 .backward()，自动计算所有的梯度，这个张量的所有梯度将会自动积累到 .grad 属性。&lt;/p&gt;

&lt;p&gt;要阻止张量跟踪历史记录，可以调用.detach()方法将其与计算历史记录分离，并禁止跟踪它将来的计算记录。&lt;/p&gt;

&lt;p&gt;在自动梯度计算中还有另外一个重要的类Function.&lt;/p&gt;

&lt;p&gt;如果需要计算导数，你可以在Tensor上调用.backward()。&lt;br /&gt;
如果Tensor是一个标量（即它包含一个元素数据）则不需要为backward()指定任何参数，但是如果它有更多的元素，你需要指定一个gradient 参数来匹配张量的形状。&lt;/p&gt;

&lt;h3 id=&quot;过程&quot;&gt;过程&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;导入包
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import torch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;创建一个张量并设置 requires_grad=True 用来追踪他的计算历史
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = torch.ones(2, 2, requires_grad=True)
print(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;对张量进行操作:
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;y = x + 2
print(y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;结果y已经被计算出来了，所以，grad_fn已经被自动生成了。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(y.grad_fn)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;对y进行一个操作
```
out = z.mean()&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;print(z, out)&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;6. .requires_grad_( ... ) 
.requires_grad_( ... ) 可以改变现有张量的 requires_grad属性。 如果没有指定的话，默认输入的flag是 False。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;a = torch.randn(2, 2)
a = ((a * 3) / (a - 1))
print(a.requires_grad)
a.requires_grad_(True)
print(a.requires_grad)
b = (a * a).sum()
print(b.grad_fn)&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;False
True
&amp;lt;SumBackward0 object at 0x000002004F7D5608&amp;gt;
```&lt;/p&gt;
&lt;h2 id=&quot;梯度&quot;&gt;梯度&lt;/h2&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="ComputerVision" /><category term="PyTorch" /><summary type="html">Autograd: 自动求导机制 PyTorch 中所有神经网络的核心是 autograd 包。 autograd包为张量上的所有操作提供了自动求导。 它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。 张量（torch.Tensor） torch.Tensor是这个包的核心类。 如果设置 .requires_grad 为 True，那么将会追踪所有对于该张量的操作。 当完成计算后通过调用 .backward()，自动计算所有的梯度，这个张量的所有梯度将会自动积累到 .grad 属性。 要阻止张量跟踪历史记录，可以调用.detach()方法将其与计算历史记录分离，并禁止跟踪它将来的计算记录。 在自动梯度计算中还有另外一个重要的类Function. 如果需要计算导数，你可以在Tensor上调用.backward()。 如果Tensor是一个标量（即它包含一个元素数据）则不需要为backward()指定任何参数，但是如果它有更多的元素，你需要指定一个gradient 参数来匹配张量的形状。 过程 导入包 import torch 创建一个张量并设置 requires_grad=True 用来追踪他的计算历史 x = torch.ones(2, 2, requires_grad=True) print(x) 对张量进行操作: y = x + 2 print(y) 结果y已经被计算出来了，所以，grad_fn已经被自动生成了。 print(y.grad_fn) 对y进行一个操作 ``` out = z.mean() print(z, out) 6. .requires_grad_( ... ) .requires_grad_( ... ) 可以改变现有张量的 requires_grad属性。 如果没有指定的话，默认输入的flag是 False。 a = torch.randn(2, 2) a = ((a * 3) / (a - 1)) print(a.requires_grad) a.requires_grad_(True) print(a.requires_grad) b = (a * a).sum() print(b.grad_fn) False True &amp;lt;SumBackward0 object at 0x000002004F7D5608&amp;gt; ``` 梯度</summary></entry><entry><title type="html">彭寒薇，生日快乐！</title><link href="http://localhost:4000/2020/02/17/%E5%BD%AD%E5%AF%92%E8%96%87%E7%94%9F%E6%97%A5%E5%BF%AB%E4%B9%90.html" rel="alternate" type="text/html" title="彭寒薇，生日快乐！" /><published>2020-02-17T00:00:00+09:00</published><updated>2020-02-17T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/17/%E5%BD%AD%E5%AF%92%E8%96%87%E7%94%9F%E6%97%A5%E5%BF%AB%E4%B9%90!</id><content type="html" xml:base="http://localhost:4000/2020/02/17/%E5%BD%AD%E5%AF%92%E8%96%87%E7%94%9F%E6%97%A5%E5%BF%AB%E4%B9%90.html">&lt;p&gt;彭寒薇，生日快乐！&lt;/p&gt;

&lt;p&gt;这个生日一定是你过得最特别的一个，也是我给别人过得最特别的一个。&lt;/p&gt;

&lt;p&gt;祝你天天快乐，每天开心！&lt;/p&gt;

&lt;div&gt;&lt;div class=&quot;extensions extensions--video&quot;&gt;
  &lt;iframe src=&quot;//player.bilibili.com/player.html?aid=89520991&amp;amp;page=1&quot; frameborder=&quot;no&quot; scrolling=&quot;no&quot; allowfullscreen=&quot;true&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="写给谁的情书" /><summary type="html">彭寒薇，生日快乐！ 这个生日一定是你过得最特别的一个，也是我给别人过得最特别的一个。 祝你天天快乐，每天开心！</summary></entry><entry><title type="html">请回答1988</title><link href="http://localhost:4000/2020/02/17/%E8%AF%B7%E5%9B%9E%E7%AD%941988.html" rel="alternate" type="text/html" title="请回答1988" /><published>2020-02-17T00:00:00+09:00</published><updated>2020-02-17T00:00:00+09:00</updated><id>http://localhost:4000/2020/02/17/%E8%AF%B7%E5%9B%9E%E7%AD%941988</id><content type="html" xml:base="http://localhost:4000/2020/02/17/%E8%AF%B7%E5%9B%9E%E7%AD%941988.html">&lt;h1 id=&quot;写在开头&quot;&gt;写在开头&lt;/h1&gt;
&lt;p&gt;又开坑了这个电视剧，这次是二刷。姑且是下载好了，之后需要多长时间才能看完就不知道了。毕竟这个电视剧每一集的时间还是很长的，而我现在也没有那么多时间都话在看电视剧上面。&lt;/p&gt;

&lt;p&gt;慢慢看，慢慢写感想吧。&lt;/p&gt;

&lt;h3 id=&quot;2020年02月17日-164957&quot;&gt;2020年02月17日 16:49:57&lt;/h3&gt;
&lt;p&gt;发现我真的是一个多情的人，今天看了三集《请回答1988》。被剧中的剧情有所触动，哭的稀里哗啦的。说好的男儿有泪不轻弹呢，到我这边就不起效果了呀。&lt;/p&gt;

&lt;p&gt;虽然是第二遍看这个电视剧了，但是时隔这么多年再看感概还是那么的真实。&lt;br /&gt;
虽然细节的剧情已经全部都忘记了，但是演员塑造的人物性格还是记着一清二楚的。&lt;/p&gt;

&lt;p&gt;我想，我喜欢这个电视剧就是因为它讲的故事特别的真实吧。&lt;br /&gt;
其实也不是什么轰轰烈烈的故事，只不过是一个胡同，一个时代背景下，普普通通的三口人家的生活。但是在我看来，确实能治愈我的心灵。&lt;br /&gt;
让我明白一些道理，也让我知道大家都是怎么生活的。&lt;/p&gt;

&lt;h3 id=&quot;2020年02月21日-153207&quot;&gt;2020年02月21日 15:32:07&lt;/h3&gt;
&lt;p&gt;果然不管是什么时间看，什么岁数看，都是很让人感动的故事啊。&lt;br /&gt;
都是些生活的小事，却显得格外的真实。&lt;/p&gt;</content><author><name>chenkaixu</name><email>chenkaixusan@gmail.com</email></author><category term="观后感" /><summary type="html">写在开头 又开坑了这个电视剧，这次是二刷。姑且是下载好了，之后需要多长时间才能看完就不知道了。毕竟这个电视剧每一集的时间还是很长的，而我现在也没有那么多时间都话在看电视剧上面。 慢慢看，慢慢写感想吧。 2020年02月17日 16:49:57 发现我真的是一个多情的人，今天看了三集《请回答1988》。被剧中的剧情有所触动，哭的稀里哗啦的。说好的男儿有泪不轻弹呢，到我这边就不起效果了呀。 虽然是第二遍看这个电视剧了，但是时隔这么多年再看感概还是那么的真实。 虽然细节的剧情已经全部都忘记了，但是演员塑造的人物性格还是记着一清二楚的。 我想，我喜欢这个电视剧就是因为它讲的故事特别的真实吧。 其实也不是什么轰轰烈烈的故事，只不过是一个胡同，一个时代背景下，普普通通的三口人家的生活。但是在我看来，确实能治愈我的心灵。 让我明白一些道理，也让我知道大家都是怎么生活的。 2020年02月21日 15:32:07 果然不管是什么时间看，什么岁数看，都是很让人感动的故事啊。 都是些生活的小事，却显得格外的真实。</summary></entry></feed>