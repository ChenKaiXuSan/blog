---
title: 机器学习基础
tag:  [ComputerVision, Python深度学习]
modify_date: 2020-05-17
---

# 机器学习的四个分支
## 监督学习
监督学习是目前最常见的机器学习类型。  
变体：
- 序列生成：给定一张图像，预测描述图像的文字。
- 语法树预测：给定一个句子，预测其分解生成的语法树。
- 目标检测：给定一张图像，在图中特定目标的周围画一个边界框。
- 图像分割：给定一张图像，在特定物体上画一个象素级的mask。

## 无监督学习
是指在没有目标的情况下寻找输入数据的有趣变换。
- 降维
- 聚类

## 自监督学习
没有人类参与的监督学习。  
标签是从输入数据中生成的，通常是使用启发式算法生成的。
- 自编码器

## 强化学习
- 智能体 
还没有工业化，未来？

# 评估机器学习模型
## 训练集，验证集和测试集
- 超参数--选择层数或每层的的大小
- 参数--权重
- 信息泄露

如果数据很少：
* 简单的留出验证
* K折验证
* 重复K折验证

### 简单的留出验证
留出一定比例的数据作为测试集。

### k折验证
将数据划分为大小相同的k个分区。

### 带有打乱数据的重复k折验证
计算代价很大

## 评估模型的注意事项
- 数据代表性
- 时间箭头
- 数据冗余

# 数据预处理，特征工程和特征学习
## 神经网络的数据预处理
目的是使原始数据更适于用神经网络处理
1. 向量化
2. 值标准化  
     输入数据应具以下特征：
    - 取值较小
    - 同质性
3. 处理缺失值

## 特征工程
用更简单的方式表述问题，从而使问题变得很容易。

# 过拟合与欠拟合
- 优化
- 泛化
- 正则化: 降低过拟合的方法

正则化方法：
## 减小网络大小
__容量__：模型中可学习参数的个数
## 添加权重正则化
- 奥卡姆剃刀原理  
一种常见的降低过拟合的方法：强制使模型权重只能选择较小的值，从而限制模型的复杂度，使得分布更加的规则。  
实现方法是向网络损失函数中添加与较大权重值相关的成本。  
两种形式：
- L1正则化：成本与权重系数的绝对值成正比
- L2正则化（权重衰减）：成本与权重系数的平方成正比
## 添加dropout正则化
对某一层使用，就是在训练过程中随机将该层的一些输出特征舍弃（设置为0）

## __总结__
防止神经网络过拟合的常用方法：
- 获得更多的训练数据
- 减小网络容量
- 添加权重正则化
- 添加dropout

# 机器学习的通用工作流程
## 定义问题，收集数据集
非平稳问题

## 选择衡量成功的指标

## 确定评估方法
## 准备数据
## 开发比基准更好的模型
目标是获得 __统计功效__  
选择三个关键参数构建第一个工作模型：
- 最后一层的激活
- 损失函数
- 优化配置

## 扩大模型规模：开发过拟合的模型
理想的模型是刚好在欠拟合和过拟合的界线上，在容量不足和容量过大的界线上。
## 模型正则化与调节超参数
应该尝试以下几项：
- 添加dropout
- 尝试不同的架构：增加或减少层数
- 添加L1或L2正则化
- 尝试不同的超参数，以找到最佳的配置
- （可选）反复做特征工程：添加新特征或删除没有信息量的特征