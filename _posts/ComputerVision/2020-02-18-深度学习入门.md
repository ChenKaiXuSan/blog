---
title: 深度学习入门
tag:  ComputerVision
---

# 神经网络的数据表示
## 张量（tensor）
使用张量作为基本数据结构。

是一个数据容器。  
它包含的数据几乎总是数值数据，因此它是数字的容器。  
矩阵是二维张量。

张量是矩阵向任意维度的推广。
张量的 **维度（dimension)** 叫做 **轴（axis）**
- 标量（0D张量）  
仅包含一个数字的张量叫做 **标量(scalar)**
- 向量（1D张量）  
数字组成的数组叫做 **向量(vector)** 或 **一维张量（1D张量）**  
一维张量只有一个轴。

- 矩阵（2D张量）  
向量组成的数组叫做 **矩阵（matrix）** 或 **二维张量（2D张量）**  
矩阵有两个轴（行和列）

- 3D张量与更高维度的张量
将多个矩阵组合成一个新的数组，可以得到一个3D张量。  
直观的理解为数字组成的立方体。

高维度张量以此类推。

## 关键属性
张量由以下三个关键属性来定义。
- 轴的个数（阶）  
3D张量有3个轴，矩阵有2个轴。
- 形状  
张量沿每个轴的维度大小（元素个数）。
- 数据类型  
张量中所包含数据的类型。  

很多库中不存在字符串张量。  
{:.warning}

## 现实世界中的数据张量
- 向量数据：2D张量
- 时间序列数据 或 序列数据：3D张量
- 图像：4D张量
- 视频：5D张量

# 张量运算
## 逐元素运算
## 广播
两个形状不同的张量进行操作，会发生什么？

较小的张量会被**广播（broadcast）**，以匹配较大张量的形状。  

广播包含以下两个步骤：

1. 向较小的张量添加轴（叫做**广播轴**）。
2. 将较小的张量沿着新轴重复，使其形状与较大张量相同。

## 张量点积
点积运算，也叫**张量积（tensor product）**。  
它将输入张量的元素合并在一起。
```
z = np.dot(x,y)
```
数学符号中
```
z = x.y
```
两个向量之间的点积是一个标量，而且只有元素个数相同的向量之间才能做点积。
{:.warning}