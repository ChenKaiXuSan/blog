---
title: 周志华《机器学习》
tag: [ComputerVision, 机器学习]
modify_date: 2020-07-14
---
# 绪论
## 基本术语
- 数据集
- 示例
- 属性/特征
- 属性值
- 属性空间/样本空间/输入空间
- 特征向量
- 维数：有几个属性就是几维
- 学习/训练：从数据中学的模型的过程，通过执行某个算法完成。
- 训练数据
  - 训练样本
  - 训练样本
  - 训练集
  - 假设：学得模型对应了关于数据的某些前在的规律
  - 真相/真实：潜在规律自身
- 预测
- 标记
- 样例：有标记信息的是示例
- 标记空间/输出空间

- 分类
  - 二分类任务
    - 正类
    - 反类
  - 多分类任务
- 回归

- 测试
- 测试样本

- 聚类
- 簇

- 监督学习：分类，回归
- 无监督学习：聚类

- 泛化
- 分布
  - 独立分布

## 假设空间
- 归纳
- 演绎
- 概念
- 版本空间

## 归纳偏好
机器学习算法在学习过程中对某种类型假设的偏好
- 奥卡姆剃刀：若有多个假设与观察一致，则选择最简单的那个
- 没有免费午餐定理：没有一种机器学习算法是适用于所有情况的

## 发展历程
## 应用现状
## 阅读材料

# 模型评估与选择
## 经验误差与过拟合
- 错误率
- 精度
- 误差
  - 训练误差/经验误差
  - 泛化误差

- 过拟合
- 欠拟合

- 模型选择问题

## 评估方法
- 测试集
- 测试误差

### 留出法
分层采样

### 交叉验证法(k折交叉验证)
留一法

### 自助法
包外估计

### 调参与最终模型
- 调参
- 验证集

## 性能度量
- 均方误差

### 错误率与精度
### 查准率，查全率与F1
- 查准率
- 查全率

- 真正例
- 真反例
- 假正例
- 假反例

- 混淆矩阵

比较学习器性能
- 平衡点（BEP）
- F1度量

有多个二分类混淆矩阵
- 宏查准率
- 宏查全率
- 宏F1

- 微查准率
- 微查全率
- 微F1

### ROC与AUC
- 分类阈值
- ROC：受试者工作特征曲线
  - 真正例率
  - 假正例率
- AUC：ROC曲线下的面积，比较不同学习器ROC性能

### 代价敏感错误率与代价曲线
- 非均等代价：衡量不同类型错误所造成的不同损失
- 代价矩阵
- 代价敏感错误率
- 代价曲线

## 比较校验
- 统计假设检验

### 假设检验
- 二项检验
  - 置信度
- t检验

### 交叉验证t检验
- 成对t检验

### McNemar检验
- 列联表

### Friedman验证与Nemenyi后续检验

## 偏差与方差
- 偏差-方差分解

- 偏差：度量了学习算法的期望预测与真实结果的偏离程度，既刻画了学习算法本身的拟合程度
- 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，既刻画了数据扰动所造成的影响
- 噪声：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，既刻画了学习问题本身的难度

- 偏差-方差窘境

# 线性模型
## 基本形式

## 线性回归
- 欧氏距离
- 最小二乘法
  - 参数估计
- 正则化项
- 对数线性回归

## 对数几率回归
- 替代函数
  - 对数几率函数
- 几率
- 对数几率
- 极大似然法

## 线性判别分析
- 类内散度矩阵
- 类间散度矩阵
- 广义瑞利商

## 多分类学习
拆分策略：
- OvO
- OvR
- MvM
  - 纠错输出编码

## 类别不平衡问题
- 再缩放
  - 欠采样
  - 过采样
  - 阈值移动

## 阅读材料
- 稀疏表示
- 多标记学习

# 决策树
## 基本流程

## 划分选择
- 纯度

### 信息增商

### 增益率
- 固有值

### 基尼指数

## 剪枝处理
- 预剪枝
- 后剪枝

### 预剪枝

### 后剪枝

## 连续与缺失值
### 连续值处理

### 缺失值处理

## 多变量决策树

# 神经网络
## 神经元模型
- 神经元
- 激活函数
  - sigmoid

## 感知机与多层网络
- 哑节点
- 学习率
- 隐含层

- 多层前馈神经网络
- 双隐层前馈网络
- 连接权

## 误差逆传播算法
- 试错法
  - 早停
  - 正则化

## 全局最小与局部极小

## 其他常见神经网络
### RBF网络
### ART网络
- 竞争型学习

### SOM网络
### 级联相关网络 
### Elman网络
- 递归神经网络
### Boltzmann机

## 深度学习