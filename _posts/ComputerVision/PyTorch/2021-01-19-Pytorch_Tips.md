---
title: Pytorch Tips
tags: [ComputerVision, PyTorch]
---

è®°å½•ä¸€ä¸‹æ˜¯ç”¨pytorchä¸­å‘ç°çš„å°æŠ€å·§ã€‚
å†™çš„å†™çš„è§‰å¾—åº”è¯¥ä¹ŸæŠŠä¸€äº›python3çš„ä¸œè¥¿æ”¾è¿›å»ã€‚  
ç„¶åè¿™ç¯‡å°±å˜æˆäº†å†™ä»£ç çš„ç¬”è®°ã€‚ğŸ¤¦â€

### 2021å¹´01æœˆ19æ—¥ 18:50:01
- .size() vs .shape, which one should be used?
  .shape is an alias for .size(), and was added to more closely match numpy
- range()æ˜¾ç¤ºçš„æ˜¯ä¸€ä¸ªèŒƒå›´ï¼Œä»å¼€å§‹åˆ°ç»“æŸã€‚åªæœ‰æ”¾åˆ°listä¸­æ‰ä¼šæ˜¾ç¤ºæ‰€æœ‰ç”Ÿæˆçš„æ•°ã€‚
  list(range(0, 5, 1)) #ä»0~4ï¼Œæ­¥é•¿1

### 2021å¹´01æœˆ20æ—¥ 11:56:07
- torch.randn å’Œ torch.rand çš„åŒºåˆ«
  - torch.randn
  Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution).
  - torch.rand
  Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1).The shape of the tensor is defined by the variable argument size.

### 2021å¹´01æœˆ25æ—¥ 11:33:44
- torch.nn.Embedding
A simple lookup table that stores embeddings of a fixed dictionary and size.  
This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.
- python3 enumerate()
enumerate() å‡½æ•°ç”¨äºå°†ä¸€ä¸ªå¯éå†çš„æ•°æ®å¯¹è±¡(å¦‚åˆ—è¡¨ã€å…ƒç»„æˆ–å­—ç¬¦ä¸²)ç»„åˆä¸ºä¸€ä¸ªç´¢å¼•åºåˆ—ï¼ŒåŒæ—¶åˆ—å‡ºæ•°æ®å’Œæ•°æ®ä¸‹æ ‡ï¼Œä¸€èˆ¬ç”¨åœ¨ for å¾ªç¯å½“ä¸­ã€‚
  ```
  >>> seasons = ['Spring', 'Summer', 'Fall', 'Winter']
  >>> list(enumerate(seasons))
  [(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]
  >>> list(enumerate(seasons, start=1))       # å°æ ‡ä» 1 å¼€å§‹
  [(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')]
  ```
- fill_(value)
Fills self tensor with the specified value.
- torch.tensor.detach()
Returns a new Tensor, detached from the current graph.
The result will never require gradient.
- torch.nn.Upsample()
Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.

### 2021å¹´01æœˆ26æ—¥ 12:09:26
- torch.nn.BatchNorm1d / torch.nn.BatchNorm2d
It is a method used to make artificial neural networks faster and more stable through normalization of the input layer by re-centering and re-scaling.
  - torch.nn.BatchNorm2d: Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension)
  - torch.nn.BatchNorm1d: 2D and 3D input.
- torch.FloatTensor / torch.cuda.FloatTensor
å‰è€…åœ¨cpuä¸Šè¿ç®—ï¼Œåè€…åœ¨gpuä¸Šè¿ç®—
- onehotç¼–ç 
one hotç¼–ç æ˜¯å°†ç±»åˆ«å˜é‡è½¬æ¢ä¸ºæœºå™¨å­¦ä¹ ç®—æ³•æ˜“äºåˆ©ç”¨çš„ä¸€ç§å½¢å¼çš„è¿‡ç¨‹ã€‚
å¦‚æœåŸæœ¬çš„æ ‡ç­¾ç¼–ç æ˜¯æœ‰åºçš„ï¼Œonehotç¼–ç ä¼šä¸¢å¤±é¡ºåºä¿¡æ¯ã€‚

### 2021å¹´01æœˆ27æ—¥ 21:26:36
- D.cuda()
Moves all model parameters and buffers to the GPU.
- å…³äºwindowç³»ç»Ÿè·¯å¾„é—®é¢˜
  - å¯ä»¥ç›´æ¥å¤åˆ¶è·¯å¾„ï¼Œä½†è¦åœ¨å‰é¢åŠ ä¸Šr''
  - æ¨èæŠŠ\æ”¹æˆ/

### 2021å¹´01æœˆ28æ—¥ 09:27:43
- torch.squeeze()
Returns a tensor with all the dimensions of input of size 1 removed.
For example, if input is of shape: (AÃ—1Ã—BÃ—CÃ—1Ã—D) then the out tensor will be of shape: (AÃ—BÃ—CÃ—D) .
- torch.stack() / torch.cat()
è¿æ¥tensorçš„æ—¶å€™ä½¿ç”¨
  - torch.stack() : å¢åŠ ä¸€ä¸ªæ–°ç»´åº¦ï¼Œç†è§£ä¸ºå åŠ 
  - torch.cat() : å¢åŠ ç°æœ‰çš„ç»´åº¦ï¼Œç†è§£ä¸ºç»­æ¥

### 2021å¹´01æœˆ29æ—¥ 17:21:03
- numpy.transpose(a)
Reverse or permute the axes of an array; returns the modified array.
For an array a with two axes, transpose(a) gives the matrix transpose.
- pickle (python3)
æ¨¡å— pickle å®ç°äº†å¯¹ä¸€ä¸ª Python å¯¹è±¡ç»“æ„çš„äºŒè¿›åˆ¶åºåˆ—åŒ–å’Œååºåˆ—åŒ–ã€‚  
  - pickle.dumps(obj, file)
  å°†å¯¹è±¡ obj å°å­˜ä»¥åçš„å¯¹è±¡å†™å…¥å·²æ‰“å¼€çš„ file object fileã€‚
- matplotlib.pyplot.imread(fname, format)
Read an image from a file into an array.